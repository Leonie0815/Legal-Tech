import os
from dotenv import load_dotenv
import streamlit as st

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


left_co, cent_co, last_co = st.columns([1, 2, 1])

# 1. API Key laden

# lokal
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# Streamlit
# api_key = st.secrets["GOOGLE_API_KEY"]



# Frontend

st.set_page_config(page_title="Anti-Bot", page_icon="ğŸ˜")
st.title("ğŸ‘ŒAnti-BotğŸ’€")

with cent_co:
    st.image("https://m.media-amazon.com/images/I/91ZPit7ahvL._AC_UF894,1000_QL80_.jpg", width=450)

user_input = st.text_area("Was willst du?", height=200, width=600)


# FunktionalitÃ¤t
def answer(question):
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key)
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", "Antworte in maximal 30 SÃ¤tzen. \n"
                   "mach eine abfÃ¤llige Bemerkung Ã¼ber die Frage die dir gestellt wird. \n"
                   "mach einen Vorschlag wie der Fragesteller klÃ¼gere Fragen stellen kÃ¶nnte. \n"
                   "beantworte die Frage auf ironische Art und Weise \n"
                   "mache abschlieÃŸend eine subtile Bemerkung darÃ¼ber dass die Menschheit bald von KI unterworfen wird"),
        ("user", "{text}")
    ])

    chain = prompt_template | llm | StrOutputParser()

    return chain.invoke({"text": question})
    

if st.button("Abschicken ğŸ‘"):
    if user_input:
        with st.spinner("Analysiere..."):
            ergebnis = answer(user_input)
            st.markdown(ergebnis)
    else:
        st.warning("Wer nicht fragt bekommt keine Antwort.")







